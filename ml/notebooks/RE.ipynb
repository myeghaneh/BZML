{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "\"\"\"A simple example of extracting relations between phrases and entities using\n",
    "spaCy's named entity recognizer and the dependency parse. Here, we extract\n",
    "money and currency values (entities labelled as MONEY) and then check the\n",
    "dependency tree to find the noun phrase they are referring to â€“ for example:\n",
    "$9.4 million --> Net income.\n",
    "Compatible with: spaCy v2.0.0+\n",
    "Last tested with: v2.1.0\n",
    "\"\"\"\n",
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import spacy\n",
    "\n",
    "\n",
    "TEXTS = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def main(model=\"en_core_web_sm\"):\n",
    "    nlp = spacy.load(model)\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "    print(\"Processing %d texts\" % len(TEXTS))\n",
    "\n",
    "   \n",
    "\n",
    "def filter_spans(spans):\n",
    "    # Filter a sequence of spans so they don't contain overlaps\n",
    "    get_sort_key = lambda span: (span.end - span.start, span.start)\n",
    "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
    "    result = []\n",
    "    seen_tokens = set()\n",
    "    for span in sorted_spans:\n",
    "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
    "            result.append(span)\n",
    "            seen_tokens.update(range(span.start, span.end))\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_currency_relations(doc):\n",
    "    # Merge entities and noun chunks into one token\n",
    "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
    "    spans = filter_spans(spans)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for span in spans:\n",
    "            retokenizer.merge(span)\n",
    "\n",
    "    relations = []\n",
    "    for money in filter(lambda w: w.ent_type_ == \"MONEY\", doc):\n",
    "        if money.dep_ in (\"attr\", \"dobj\"):\n",
    "            subject = [w for w in money.head.lefts if w.dep_ == \"nsubj\"]\n",
    "            if subject:\n",
    "                subject = subject[0]\n",
    "                relations.append((subject, money))\n",
    "        elif money.dep_ == \"pobj\" and money.head.dep_ == \"prep\":\n",
    "            relations.append((money.head.head, money))\n",
    "    return relations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net income\tMONEY\t$9.4 million\n",
      "the prior year\tMONEY\t$2.7 million\n",
      "Revenue   \tMONEY\ttwelve billion dollars\n",
      "a loss    \tMONEY\t1b\n"
     ]
    }
   ],
   "source": [
    "model=\"en_core_web_sm\"\n",
    "nlp = spacy.load(model)\n",
    "for text in TEXTS:\n",
    "        doc = nlp(text)\n",
    "        relations = extract_currency_relations(doc)\n",
    "        for r1, r2 in relations:\n",
    "            print(\"{:<10}\\t{}\\t{}\".format(r1.text, r2.ent_type_, r2.text))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=nlp('Net income was $9.4 million compared to the prior year of $2.7 million.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "($9.4 million, the prior year, $2.7 million)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator at 0x2ea338a7a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.noun_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net income\n",
      "the prior year\n"
     ]
    }
   ],
   "source": [
    "for n in doc.noun_chunks:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leadeed by\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "verb = \"<ADV>*<AUX>*<VBN><IN|PART>*<ADV>*\"\n",
    "word = \"<NOUN|ADJ|ADV|DET|ADP>\"\n",
    "preposition = \"<ADP|ADJ>\"\n",
    "\n",
    "rel_pattern = \"( %s (%s* (%s)+ )? )+ \" % (verb, word, preposition)\n",
    "grammar_long = '''REL_PHRASE: {%s}''' % rel_pattern\n",
    "reverb_pattern = nltk.RegexpParser(grammar_long)\n",
    "\n",
    "#sent = \"where the equation caused by the eccentricity is maximum.\"\n",
    "sent= \" corruption leadeed by fuck\"\n",
    "sent_pos_tags = nltk.tag.pos_tag(sent.split())\n",
    "\n",
    "for x in reverb_pattern.parse(sent_pos_tags):\n",
    "    if isinstance(x, nltk.Tree) and x.label() == 'REL_PHRASE':\n",
    "        rel_phrase = \" \".join([t[0] for t in x.leaves()])\n",
    "        print(rel_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('corruption', 'NN'), ('caused', 'VBN'), ('by', 'IN'), ('corruption', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leadeed by'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_phrase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
