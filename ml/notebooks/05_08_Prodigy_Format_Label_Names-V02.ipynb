{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex and Prodigy (LABEL: Names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= \"3\">\n",
    "Annotation of entities for sentences based on prodigy's format for different labels for further usage in Machine learning. Prodigy is an annotation tool based on spaCy. Please see here:\n",
    "    </p>\n",
    "  <a href=\"https://prodi.gy/ \"> Prodigy </a> \n",
    "<font 3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import spacy \n",
    "from prodigy.util import write_jsonl\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "importVersion = '013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path= '../data/01_df_v{0}.pickle'.format(importVersion)# Put the path of the data in your local machine here, consider the letter \"r\" before the path\n",
    "dfAstroNova = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort based on the Chapter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data based on the chapters of the book \n",
    "dfAstroNova['chapter'] = dfAstroNova.chapter.replace(\"appendix b\",np.nan).astype(float)  \n",
    "dfAstroNova = dfAstroNova.rename_axis('MyIdx').sort_values(by = ['chapter', 'MyIdx'], ascending = [True, True])\n",
    "dfAstroNova.chapter.fillna('appendix b', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAstroNova.reset_index(inplace=True)\n",
    "dfAstroNova=dfAstroNova.drop(\"MyIdx\",axis=1,inplace=False)\n",
    "dfAstroNova=dfAstroNova.drop(\"html\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfAstroNova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>links</th>\n",
       "      <th>italic</th>\n",
       "      <th>chapter</th>\n",
       "      <th>graphic</th>\n",
       "      <th>table</th>\n",
       "      <th>marginal</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Chapter 1]</td>\n",
       "      <td>[[(Chapter, None), (1, NUM)]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the distinction between the first motion an...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[On the distinction between the first motion a...</td>\n",
       "      <td>[[(On, None), (the, None), (distinction, None)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The testimony of the ages confirms that the mo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ Terms: 1. The first motion is that of the wh...</td>\n",
       "      <td>[The testimony of the ages confirms that the m...</td>\n",
       "      <td>[[(The, None), (testimony, None), (of, None), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is just this from which astronomy arose amo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[ ch 1 gr 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[It is just this from which astronomy arose am...</td>\n",
       "      <td>[[(It, None), (is, None), (just, None), (this,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Before the distinction between the first motio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(such]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ 2]</td>\n",
       "      <td>[Before the distinction between the first moti...</td>\n",
       "      <td>[[(Before, None), (the, None), (distinction, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text links   italic chapter  \\\n",
       "0                                          Chapter 1    []       []       1   \n",
       "1  On the distinction between the first motion an...    []       []       1   \n",
       "2  The testimony of the ages confirms that the mo...    []       []       1   \n",
       "3  It is just this from which astronomy arose amo...    []       []       1   \n",
       "4  Before the distinction between the first motio...    []  [(such]       1   \n",
       "\n",
       "        graphic table                                           marginal  \\\n",
       "0            []    []                                                 []   \n",
       "1            []    []                                                 []   \n",
       "2            []    []  [ Terms: 1. The first motion is that of the wh...   \n",
       "3  [ ch 1 gr 1]    []                                                 []   \n",
       "4            []    []                                               [ 2]   \n",
       "\n",
       "                                           sentences  \\\n",
       "0                                        [Chapter 1]   \n",
       "1  [On the distinction between the first motion a...   \n",
       "2  [The testimony of the ages confirms that the m...   \n",
       "3  [It is just this from which astronomy arose am...   \n",
       "4  [Before the distinction between the first moti...   \n",
       "\n",
       "                                              tagged  \n",
       "0                      [[(Chapter, None), (1, NUM)]]  \n",
       "1  [[(On, None), (the, None), (distinction, None)...  \n",
       "2  [[(The, None), (testimony, None), (of, None), ...  \n",
       "3  [[(It, None), (is, None), (just, None), (this,...  \n",
       "4  [[(Before, None), (the, None), (distinction, N...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAstroNova.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfAstroNova.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=[]\n",
    "for para in dfAstroNova.sentences:\n",
    "    sents +=para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Based on Consistant format with Prodigy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<fig size= 3>\n",
    "Prodigy accept a specific format; a JSONL format (newline-delimited JSON). Entities and other highlighted spans of text can be defined in the \"spans\" property. A example could look like this dictionary:\n",
    "</p>    \n",
    "text': 'On 1595 October 30 at 8h 20m, they found Mars at 17° 48’ Taurus, with a diurnal motion of 22’ 54” ^15.',\n",
    "  'spans': [{'start': 22, 'end': 29, 'label': 'TIME'}]}\n",
    "</p>\n",
    "which start and end's numbers refer to the position of entitiy  in the sentence. (here STAR,PLAN, NAME)\n",
    "\n",
    "    \n",
    "<fig size>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here since the correction of annotation is not very hard, we annotate 3 follwoing labels: </p>\n",
    "<ul>\n",
    "<li>STAR: stars's names </li>\n",
    "<li>PLAN: planet's names </li>\n",
    "<li>NAME: names of people and places </li>\n",
    "</ul>\n",
    "and then we  merge the results for correction by annotators.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"STAR\"   \n",
    "texts = sents  \n",
    "regex_patterns = [\n",
    "re.compile(r'(\\bAldebaran\\b|\\bAlphard\\b|\\bAntares\\b|\\bArcturus\\b|\\bBack of Leo\\b|\\bBeta Leonis\\b|\\bBeta Scorpii\\b|\\bBeta Tauri\\b|\\bBetelgeuse\\b|\\bcanis\\b|\\bCanis Minor\\b|\\bCor Leonis\\b|\\bCor Scorpii,10\\b|\\bCor Scorpii\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bAldebaran\\b|\\bAlphard|\\bAntares\\b|\\bArcturus\\b|\\bBack of Leo\\b|\\bBeta Leonis\\b|\\bBeta Scorpii\\b|\\b\\Beta Tauri\\b|\\bBetelgeuse\\b|\\bcanis\\b|\\bCanis Minor\\b|\\bCor Leonis\\b|\\bCor Scorpii\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bHeart of Hydra\\b|\\bHydrae\\b|\\bKappa Geminorum\\b|\\bLambda Leonis\\b|\\bNeck of Leo\\b|\\bOrion\\b|\\bPalilicium\\b|\\bPolaris\\b|\\bPollux\\b|\\bProcyon\\b|\\bRegulus\\b|\\bSpica Virginis\\b|\\bTail of Leo\\b|\\bUrsa\\b|\\bUrsa Major\\b|\\bVindemiatrix\\b|\\bZeta Leonis\\b)')\n",
    "]\n",
    "examples = []\n",
    "for text in texts:\n",
    "    for expression in regex_patterns:\n",
    "    \n",
    "        spans = []\n",
    "    for match in re.finditer(expression, text):\n",
    "        start, end = match.span()\n",
    "        span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "        spans.append(span)\n",
    "    task = {\"text\": text, \"spans\": spans}\n",
    "    examples.append(task)              \n",
    "\n",
    "#write_jsonl(\"NER_STAR_01.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misaligned_token(examples):\n",
    "    counter=0\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  \n",
    "    for example in examples:  \n",
    "        doc = nlp(example[\"text\"])\n",
    "        for span in example[\"spans\"]:\n",
    "            char_span = doc.char_span(span[\"start\"], span[\"end\"])\n",
    "            if char_span is None:  \n",
    "                counter+=1\n",
    "                print(\"{}- Misaligned tokens-->\".format(counter), example[\"text\"],span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- Misaligned tokens--> Again, at 7h 15m on the morning of December 27, it was 36° 43’ from Cor Leonis,7 whose latitude is 0° 26½’; hence, its longitude at the end of 1582 is 17° 28⅓’ Cancer, altitude 14° 4’, and thus affected by refraction. {'start': 68, 'end': 78, 'label': 'STAR'}\n",
      "2- Misaligned tokens--> [IV] On 1590 October 6, at 4h 45m in the morning, Mars was observed at an altitude of 12½ degrees, [and distances taken] from the Tail of Leo7 and the Heart of Hydra,8 with its declination. {'start': 151, 'end': 165, 'label': 'STAR'}\n",
      "3- Misaligned tokens--> From this time interval, by the principles laid down above, the sun's mean motion is found to have gone 5s 25° 32' 50\" beyond Cor Leonis,7 with an anomaly of 234° 54' 34\" . {'start': 126, 'end': 136, 'label': 'STAR'}\n"
     ]
    }
   ],
   "source": [
    "misaligned_token(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear from above , After using regular expression we faced with some specific format like these words:\n",
    "- Cor Leonis,7\n",
    "- Hydra,8\n",
    "- Cor Leonis,7\n",
    "\n",
    "We consider these words as edge cases which means tokens are not consistant with the tokens assigned by the model’s tokenizer. here we have a samll set of edge cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Possible Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify our annotation rules based on the above examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"STAR\"   \n",
    "texts = sents  \n",
    "regex_patterns = [\n",
    "re.compile(r'(\\bAldebaran\\b|\\bAlphard\\b|\\bAntares\\b|\\bArcturus\\b|\\bBack of Leo\\b|\\bBeta Leonis\\b|\\bBeta Scorpii\\b|\\bBeta Tauri\\b|\\bBetelgeuse\\b|\\bcanis\\b|\\bCanis Minor\\b|\\bCor Leonis,7\\b|\\bCor Leonis\\b|\\bCor Scorpii,10\\b|\\bCor Scorpii\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bAldebaran\\b|\\bAlphard|\\bAntares\\b|\\bArcturus\\b|\\bBack of Leo\\b|\\bBeta Leonis\\b|\\bBeta Scorpii\\b|\\b\\Beta Tauri\\b|\\bBetelgeuse\\b|\\bcanis\\b|\\bCanis Minor\\b|\\bCor Leonis,7\\b|\\bCor Leonis\\b|\\bCor Scorpii\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bDenebola\\b|\\bdog\\b|\\bEpsilon Virginis\\b|\\bErichthonius\\b|\\bHeart of Hydra,8|\\bHeart of Hydra\\b|\\bHydrae\\b|\\bKappa Geminorum\\b|\\bLambda Leonis\\b|\\bNeck of Leo\\b|\\bOrion\\b|\\bPalilicium\\b|\\bPolaris\\b|\\bPollux\\b|\\bProcyon\\b|\\bRegulus\\b|\\bSpica Virginis\\b|\\bTail of Leo\\b|\\bUrsa\\b|\\bUrsa Major\\b|\\bVindemiatrix\\b|\\bZeta Leonis\\b)[:,]?')\n",
    "]\n",
    "examples = []\n",
    "for text in texts:\n",
    "    for expression in regex_patterns:\n",
    "    \n",
    "        spans = []\n",
    "    for match in re.finditer(expression, text):\n",
    "        start, end = match.span()\n",
    "        span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "        spans.append(span)\n",
    "    task = {\"text\": text, \"spans\": spans}\n",
    "    examples.append(task)              \n",
    "\n",
    "write_jsonl(\"NER_STAR_V02.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "misaligned_token(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"PLAN\"   \n",
    "texts = sents\n",
    "regex_patterns = [\n",
    "re.compile(r'(\\bEarth\\b|\\bJupiter\\b|\\bMars\\b|\\bMercury\\b|\\bMoon\\b|\\bNeptune\\b|\\bPluto\\b|\\bSaturn\\b|\\bSun\\b|\\bUranus\\b|\\bVenus\\b)')\n",
    "]\n",
    "examples = []\n",
    "for text in texts:\n",
    "    for expression in regex_patterns:\n",
    "    \n",
    "        spans = []\n",
    "    for match in re.finditer(expression, text):\n",
    "        start, end = match.span()\n",
    "        span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "        spans.append(span)\n",
    "    task = {\"text\": text, \"spans\": spans}\n",
    "    examples.append(task)              \n",
    "\n",
    "#write_jsonl(\"NER_PLAN_01.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- Misaligned tokens--> If this wearisome method has filled you with loathing, it should more properly fill you with compassion for me, as I have gone through it at least seventy times at the expense of a great deal of time, and you will cease to wonder that the fifth year has now gone by since I took up Mars,12 although the year 1603 was nearly all given over to optical investigations. {'start': 282, 'end': 286, 'label': 'PLAN'}\n"
     ]
    }
   ],
   "source": [
    "misaligned_token(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear from above , After using regular expression we faced with some specific format like these words:\n",
    "- Mars,12\n",
    "\n",
    "\n",
    "We consider these words as edge cases which means tokens are not consistant with the tokens assigned by the model’s tokenizer. here we have only one edge case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Possible Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify our annotation rules based on the above examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"PLAN\"   \n",
    "texts = sents\n",
    "regex_patterns = [\n",
    "re.compile(r'(\\bEarth\\b|\\bJupiter\\b|\\bMars,12\\b|\\bMars\\b|\\bMercury\\b|\\bMoon\\b|\\bNeptune\\b|\\bPluto\\b|\\bSaturn\\b|\\bSun\\b|\\bUranus\\b|\\bVenus\\b)')\n",
    "]\n",
    "examples = []\n",
    "for text in texts:\n",
    "    for expression in regex_patterns:\n",
    "    \n",
    "        spans = []\n",
    "    for match in re.finditer(expression, text):\n",
    "        start, end = match.span()\n",
    "        span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "        spans.append(span)\n",
    "    task = {\"text\": text, \"spans\": spans}\n",
    "    examples.append(task)              \n",
    "\n",
    "write_jsonl(\"NER_PLAN_V02.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misaligned_token(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"NAME\"   \n",
    "texts = sents \n",
    "regex_patterns = [\n",
    "re.compile(r'(\\bAlbategnius\\b|\\bAlexandria\\b|\\bApanius\\b|\\bApollonius\\b|\\bApollonius of Perga\\b|\\bAristarchus\\b|\\bAristotelian\\b|\\bAristotle\\b|\\bArzachel\\b|\\bBaron Friedrich Hoffmann\\b|\\bBohemia\\b|\\bBrahean\\b|\\bChristian Severinus\\b|\\bCopernican\\b|\\bCopernicus\\b|\\bDiogenes Laertius\\b|\\bDiogenes Laertius\\b|\\bEast Frisia\\b|\\bFabrician\\b|\\bFabricius|\\bHipparchus\\b|\\bHven\\b|\\bJohann Schuler\\b|\\bLansberg\\b|\\bongomontanus\\b|\\bMaestlin\\b|\\bBetelgeuse\\b|\\bMagini\\b|\\bMatthias Seiffard\\b|\\bPatricius\\b|\\bPeurbach\\b|\\bPrague\\b|\\bPrutenics\\b|\\bPtolemaic\\b|\\bPythagoreans\\b|\\bRheticus\\b|\\bScaliger\\b|\\bStadius\\b|\\bTheodesius \\b|\\bTycho Brahe\\b|\\bUraniborg|\\bZalippus\\b)')\n",
    "]\n",
    "\n",
    "\n",
    "examples = []\n",
    "for text in texts:\n",
    "    for expression in regex_patterns:\n",
    "    \n",
    "        spans = []\n",
    "    for match in re.finditer(expression, text):\n",
    "        start, end = match.span()\n",
    "        span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "        spans.append(span)\n",
    "    task = {\"text\": text, \"spans\": spans}\n",
    "    examples.append(task)              \n",
    "\n",
    "#write_jsonl(\"NER_NAME_01.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Misaligned Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<fig size= 3>\n",
    "This step is very important, since if Pordigy faces with Misaligned tokens, we can see that before and try to adjust regex accordingly\n",
    "<fig size>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misaligned_token(examples):\n",
    "    counter=0\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  \n",
    "    for example in examples:  \n",
    "        doc = nlp(example[\"text\"])\n",
    "        for span in example[\"spans\"]:\n",
    "            char_span = doc.char_span(span[\"start\"], span[\"end\"])\n",
    "            if char_span is None:  \n",
    "                counter+=1\n",
    "                print(\"{}- Misaligned tokens-->\".format(counter), example[\"text\"],span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1- Misaligned tokens--> Those with more experience consider them with good reason to be incompetent, or (if, like that man Patricius,4 they want to be known as philosophers) to act mad with reasoning. {'start': 99, 'end': 109, 'label': 'NAME'}\n",
      "2- Misaligned tokens--> The followers of Aristotle, and even Scaliger,6 who professes to be a Christian, openly contend that this motion of the orbs is voluntary, and that the principle of volition for them is intellectual intuition and desire. {'start': 37, 'end': 46, 'label': 'NAME'}\n",
      "3- Misaligned tokens--> For in Maestlin,4 on the twelfth at noon, Mars is put at 8° 20’ Gemini, and on the seventeenth, again at noon, it is at 6° 25’ Gemini. {'start': 7, 'end': 16, 'label': 'NAME'}\n",
      "4- Misaligned tokens--> In Stadius,5 it is 1° 52’. {'start': 3, 'end': 11, 'label': 'NAME'}\n",
      "5- Misaligned tokens--> 18/28 at 10h 30m, using the Tychonic  instruments (with the help of the learned Matthias Seiffard,22 bequeathed us by Tycho), I took the distance of Mars from the middle star of the tail of Ursa Major 23 to be 52° 22’. {'start': 80, 'end': 98, 'label': 'NAME'}\n",
      "6- Misaligned tokens--> Therefore, since our time follows by 4 days 15h 49m, to which corresponds 1° 28' of motion from Magini,26 we shall add 1° 27' according to the above ratio. {'start': 96, 'end': 103, 'label': 'NAME'}\n",
      "7- Misaligned tokens--> Thus, David Fabricius2 was able to use his observations to charge my hypothesis of Chapter 45, which I had communicated to him as true, with this error of having distances that are too short at the middle elongations, writing at the very time when I was laboring to seek out the true hypothesis with renewed care. {'start': 12, 'end': 21, 'label': 'NAME'}\n",
      "8- Misaligned tokens--> For those found today by Brahe, and those found several centuries ago by Albategnius and Arzachel,8 are nearly the same. {'start': 89, 'end': 98, 'label': 'NAME'}\n"
     ]
    }
   ],
   "source": [
    "misaligned_token(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear from above , After using regular expression we faced with some specific format like these words:\n",
    "- Stadius,5\n",
    "- Scaliger,6\n",
    "- Patricius,4\n",
    "- Matthias Seiffard,22\n",
    "- Magini,26\n",
    "- Maestlin,4\n",
    "- Fabricius2\n",
    "- Brahe,7 \n",
    "- Arzachel,8\n",
    "\n",
    "We consider these words as edge cases which means tokens are not consistant with the tokens assigned by the model’s tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Possible Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify our annotation rules based on the above examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "    label = \"NAME\"   \n",
    "    texts = sents  \n",
    "    regex_patterns = [\n",
    "    re.compile(r'(\\bAlbategnius\\b|\\bAlexandria\\b|\\bApanius\\b|\\bApollonius\\b|\\bApollonius of Perga\\b|\\bAristarchus\\b|\\bAristotelian\\b|\\bAristotle\\b|\\bArzachel,8\\b|\\bArzachel\\b|\\bBaron Friedrich Hoffmann\\b|\\bBohemia\\b|\\bBrahe,7\\b|\\bBrahean\\b|\\bChristian Severinus\\b|\\bCopernican\\b|\\bCopernicus\\b|\\bDiogenes Laertius\\b|\\bDiogenes Laertius\\b|\\bEast Frisia\\b|\\bFabrician\\b|\\bFabricius2\\b|\\bFabricius|\\bHipparchus\\b|\\bHven\\b|\\bJohann Schuler\\b|\\bLansberg\\b|\\bongomontanus\\b|\\bMaestlin,4\\b|\\bMaestlin\\b|\\bBetelgeuse\\b|\\bMagini,26\\b\\bMagini\\b|\\bMatthias Seiffard,22\\b|\\bMatthias Seiffard\\b|\\bPatricius,4\\b|\\bPatricius\\b|\\bPeurbach\\b|\\bPrague\\b|\\bPrutenics\\b|\\bPtolemaic\\b|\\bPythagoreans\\b|\\bRheticus\\b|\\bScaliger,6\\b|\\bScaliger\\b|\\bStadius,5\\b|\\bStadius\\b|\\bTheodesius \\b|\\bTycho Brahe\\b|\\bUraniborg|\\bZalippus\\b)')\n",
    "    ]\n",
    "\n",
    "\n",
    "    examples = []\n",
    "    for text in texts:\n",
    "        for expression in regex_patterns:\n",
    "\n",
    "            spans = []\n",
    "        for match in re.finditer(expression, text):\n",
    "            start, end = match.span()\n",
    "            span = {\"start\": start, \"end\": end, \"label\": label}\n",
    "            spans.append(span)\n",
    "        task = {\"text\": text, \"spans\": spans}\n",
    "        examples.append(task)              \n",
    "\n",
    "    write_jsonl(\"NER_NAME_V02.jsonl\", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "misaligned_token(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
