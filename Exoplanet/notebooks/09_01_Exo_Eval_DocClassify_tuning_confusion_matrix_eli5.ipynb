{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Classification ( In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=[\"ner\", \"textcat\", \"entity_ruler\", \"merge_noun_chunks\", \"merge_entities\", \"merge_subtokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-198a07fd4b11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDictVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"compact\": True, \"bg\": \"#09a3d5\",\n",
    "           \"color\": \"white\", \"font\": \"Source Sans Pro\",\"collapse_phrases\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('max_colwidth', 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExoplanetsNASAannot = pd.read_json('../data/dfExoplanetsNASAdetected100rand_v2.json', orient = 'table')\n",
    "del dfExoplanetsNASAannot['tagRootSent']\n",
    "del dfExoplanetsNASAannot['tagDetected']\n",
    "dfExoplanetsNASAannot.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satz_analytic2(satz):\n",
    "#    merkmal = dict({\"satz\":satz.text})\n",
    "    merkmal=dict({})\n",
    "# search for main verb\n",
    "    for t in satz:\n",
    "        if t.dep_ == \"ROOT\":\n",
    "            r=t.head.text\n",
    "            merkmal.update({\"act\":r})\n",
    "# subject and object related to verb\n",
    "    for t in satz:\n",
    "#        if t.dep_ == \"dobj\" and merkmal[\"act\"]==t.head.text:\n",
    "#            merkmal.update({\"obj\":''.join(w.text_with_ws for w in t.subtree)})\n",
    "        if t.dep_ == \"nsubj\" and merkmal[\"act\"]==t.head.text:\n",
    "            merkmal.update({\"subject\":t.text.lower()})\n",
    "\n",
    "    return(merkmal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExoplanetsNASAannot[\"s\"]=dfExoplanetsNASAannot[\"sent\"].apply(lambda y: satz_analytic2(nlp(y)))\n",
    "dfExoplanetsNASAannot.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_xs=list(dfExoplanetsNASAannot[\"sent\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_ys=np.array(list(dfExoplanetsNASAannot[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transp(x):\n",
    "    if x==\"discovery\":\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "    return(y)\n",
    "dfExoplanetsNASAannot[\"label\"]=dfExoplanetsNASAannot[\"label\"].apply(lambda x: transp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExoplanetsNASAannot.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_xs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list(dfExoplanetsNASAannot[\"sent\"])\n",
    "y=np.array(list(dfExoplanetsNASAannot[\"label\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Category=Counter(y)\n",
    "Counter=dict(Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(Counter.keys()),Counter.values(),color=\"r\",width=.4,tick_label=[\"1:discovery\",\"0:None\"])\n",
    "plt.title(\"Distribution of samples over different classes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X,y, test_size=0.25, random_state=42)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while training and buliding a model, we should keep in mind that there is never the best one. It is realtively experimental process. We start to try different trials. we trired different evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tried the following models:\n",
    "- Multinomial Naïve Bayes\n",
    "- XGBoosts classifier\n",
    "- Random Forest\n",
    "- Support Vector Machine\n",
    "-  SGD Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_accuracy(clf,X,y):\n",
    "    scores = cross_val_score(clf, X, y, cv=3)\n",
    "    print(scores)\n",
    "    print('Accuracy of : {:.3f} ± {:.3f}'.format(np.mean(scores), 2 * np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Color_Confusion_Matrix(y, y_test, y_pred):\n",
    "    cm=confusion_matrix(y_test, y_pred)\n",
    "    l=len(set(y))\n",
    "    df_cm = pd.DataFrame(cm, range(l), range(l))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.heatmap(df_cm,cmap=\"Blues\", annot=True,annot_kws={\"size\": 16})\n",
    "    plt.ylabel('True label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    plt.title(\"Confusion Matrix\", size = 16)\n",
    "    plt.savefig('CM_Test_01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve  \n",
    "from sklearn.metrics import roc_auc_score \n",
    "def plot_roc_curve(fpr, tpr,auc):  \n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve with AUC {:.3f}'.format(AUC))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 01-Naive Bayes\n",
    "trial_01=Pipeline([ ('vectorizer', TfidfVectorizer()), ('classifier', MultinomialNB())])\n",
    "################################################################################\n",
    "\n",
    "## 02-XGBClassifier\n",
    "trial_02 = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('clf', XGBClassifier())])\n",
    "################################################################################\n",
    "## 03-Random Forest Classifier\n",
    "trial_03= Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=1000, random_state=0))])\n",
    "\n",
    "################################################################################\n",
    "## 04-SVC Classifier\n",
    "vec = TfidfVectorizer(min_df=3,ngram_range=(1, 2))\n",
    "svd = TruncatedSVD()\n",
    "pipe = make_pipeline(vec, svd)\n",
    "clf = SVC()\n",
    "trial_04 = make_pipeline(pipe, clf)\n",
    "\n",
    "#################################################################################\n",
    "# 05- SGD Classifier\n",
    "vec=TfidfVectorizer()\n",
    "clf= SGDClassifier()\n",
    "trial_05=Pipeline([(\"vect\",vec),(\"clf\",clf)])\n",
    "\n",
    "#################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Prediction by XGBCalssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=train_predict(trial_02,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we used classification report and confusion matrix for a test set  . Then we show the result of classifcation report and confusion matrix over ten folds to have unibased evaluation metrics. here we have chosen two models among 5 models that we tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## a) train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "Color_Confusion_Matrix(y=y,y_test=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) 10 fold cross valdiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_accuracy(trial_02,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(trial_02, X, y, cv=10)\n",
    "cr=classification_report(y,y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_pred,y)\n",
    "Color_Confusion_Matrix(y=y,y_test=y,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve and AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y,y_pred)  \n",
    "fpr, tpr, thresholds = roc_curve(y,y_pred) \n",
    "plot_roc_curve(fpr,tpr,AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Prediction by SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=train_predict(trial_05,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "Color_Confusion_Matrix(y=y,y_test=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) 10 fold cross valdiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_accuracy(trial_05,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(trial_05, X, y, cv=10)\n",
    "cr=classification_report(y,y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_pred,y)\n",
    "Color_Confusion_Matrix(y=y,y_test=y,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curve and AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y,y_pred)  \n",
    "fpr, tpr, thresholds = roc_curve(y,y_pred) \n",
    "plot_roc_curve(fpr,tpr,AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning on XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid= {\n",
    "    'vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "   'clf__max_iter' : [400],\n",
    "   'clf__tol' : np.logspace(-4,0,5)\n",
    "}\n",
    "trial_02_01 = GridSearchCV(trial_02, param_grid=param_grid, cv=3, n_jobs=-1, verbose=0, error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_02_01.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_02_01=trial_02_01.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf_02_01.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation after parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "Color_Confusion_Matrix(y=y,y_test=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_accuracy(trial_02_01,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(trial_02_01, X, y, cv=5)\n",
    "cr=classification_report(y,y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_pred,y)\n",
    "Color_Confusion_Matrix(y=y,y_test=y,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y,y_pred)  \n",
    "fpr, tpr, thresholds = roc_curve(y,y_pred) \n",
    "plot_roc_curve(fpr,tpr,AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see the results are improved by parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning on SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_01= {\n",
    "    'clf__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e-1, 1e2, 1e3], # learning rate\n",
    "    'clf__n_iter': [1000], # number of epochs\n",
    "    'clf__loss': ['log'], \n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__n_jobs': [-1]\n",
    "}\n",
    "trial_05_01 = GridSearchCV(trial_05, param_grid=param_grid_01, cv=5, n_jobs=-1, verbose=0, error_score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_05_01.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_05_01=trial_05_01.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=train_predict(clf_05_01,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation after parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "Color_Confusion_Matrix(y=y,y_test=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_accuracy(clf_05_01,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(clf_05_01, X, y, cv=5)\n",
    "cr=classification_report(y,y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_pred,y)\n",
    "Color_Confusion_Matrix(y=y,y_test=y,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = roc_auc_score(y,y_pred)  \n",
    "fpr, tpr, thresholds = roc_curve(y,y_pred) \n",
    "plot_roc_curve(fpr,tpr,AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining prediction by XGB classifier using eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5 import show_weights\n",
    "show_weights(trial_05, top=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.show_prediction(clf, X_train[22],vec=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, X_train[28],vec=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, X_train[55],vec=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(clf, X_train[25],vec=vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject Object features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELi5's explanation can give us a motivation to work on subject (also object) features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f=list(dfExoplanetsNASAannot[\"s\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features here are subjects and objects as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shuffle(X_f, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X,y, test_size=0.25, random_state=42)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB classifier on subject-object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "vec = DictVectorizer()\n",
    "pipeline = make_pipeline(vec, clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_accuracy(pipeline,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=train_predict(pipeline,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=classification_report(y_test,y_pred)\n",
    "print(cr)\n",
    "Color_Confusion_Matrix(y=y,y_test=y_test,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(pipeline, X, y, cv=5)\n",
    "cr=classification_report(y,y_pred)\n",
    "print(cr)\n",
    "cm = confusion_matrix(y_pred,y)\n",
    "Color_Confusion_Matrix(y=y,y_test=y,y_pred=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
